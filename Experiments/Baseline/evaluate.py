import time
import sys
import os
from ultralytics import YOLO
from datetime import datetime

sys.path.insert(0, "./ultralytics")  # ä½¿ç”¨æœ¬åœ° ultralytics æºç 

def evaluate(model_path, data_yaml, save_preds=True, tag="baseline_test"):
    print(f"\nğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)

    # æ¨¡å‹ç»“æ„ä¿¡æ¯
    print("\nğŸ“Š æ¨¡å‹ç»“æ„åˆ†æï¼š")
    model_info = model.info(verbose=True)

    # ç²¾åº¦è¯„ä¼°ï¼ˆæµ‹è¯•é›†ï¼‰
    print("\nğŸ¯ ç²¾åº¦è¯„ä¼°ï¼ˆæµ‹è¯•é›† mAPï¼‰")
    metrics = model.val(data=data_yaml, split='test', verbose=False)
    mAP50 = metrics.box.map50
    mAP5095 = metrics.box.map

    print(f"\nâœ… mAP@0.5     : {mAP50:.4f}")
    print(f"âœ… mAP@0.5:0.95: {mAP5095:.4f}")

    # æ¨ç†é€Ÿåº¦è¯„ä¼°
    print("\nâš¡ æ¨ç†é€Ÿåº¦è¯„ä¼°ä¸­ï¼ˆFPSï¼‰...")
    t0 = time.time()
    results = model.predict(
        source="../../Datasets/images/test",
        save=save_preds,
        conf=0.25,
        project="runs",
        name=f"eval_{tag}",
        exist_ok=True,
        verbose=False
    )
    t1 = time.time()
    n = len(results)
    total_time = t1 - t0
    fps = n / total_time

    print(f"\nğŸ“¸ æ¨ç†å›¾ç‰‡æ•°ï¼š{n}")
    print(f"â±ï¸ æ€»è€—æ—¶ï¼š{total_time:.2f}s")
    print(f"ğŸš€ å¹³å‡FPSï¼š{fps:.2f} å¼ /ç§’")

    # ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ¨¡å‹æ‰€åœ¨ç›®å½•
    eval_text = f"""Model Evaluation Summary
Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Model path: {model_path}
Image size: 640

ğŸ“Š Model Info:
{model_info}

ğŸ¯ Accuracy:
mAP@0.5     : {mAP50:.4f}
mAP@0.5:0.95: {mAP5095:.4f}

âš¡ Inference:
Image count : {n}
Total time  : {total_time:.2f}s
FPS         : {fps:.2f}
"""

    model_dir = os.path.dirname(model_path)
    eval_path = os.path.join(model_dir, "best_eval.txt")
    with open(eval_path, "w", encoding="utf-8") as f:
        f.write(eval_text)

    print(f"\nğŸ“„ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°ï¼š{eval_path}")

if __name__ == "__main__":
    evaluate(
        model_path="C:/Users/user/Desktop/best.pt",
        data_yaml="data.yaml",
        save_preds=True,
        tag="baseline_test"
    )
